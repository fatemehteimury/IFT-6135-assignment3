{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASS3_Q3_quantitative.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3QujZsLxhIRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#src = list(files.upload().values())[0]\n",
        "#open('classify_svhn.py','wb').write(src)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UZ6VnZ_h2c0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import classify_svhn\n",
        "from classify_svhn import Classifier\n",
        "import numpy as np\n",
        "\n",
        "SVHN_PATH = \"svhn\"\n",
        "PROCESS_BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def get_sample_loader(path, batch_size):\n",
        "    \"\"\"\n",
        "    Loads data from `[path]/samples`\n",
        "\n",
        "    - Ensure that path contains only one directory\n",
        "      (This is due ot how the ImageFolder dataset loader\n",
        "       works)\n",
        "    - Ensure that ALL of your images are 32 x 32.\n",
        "      The transform in this function will rescale it to\n",
        "      32 x 32 if this is not the case.\n",
        "\n",
        "    Returns an iterator over the tensors of the images\n",
        "    of dimension (batch_size, 3, 32, 32)\n",
        "    \"\"\"\n",
        "    data = torchvision.datasets.ImageFolder(\n",
        "        path,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Resize((32, 32), interpolation=2),\n",
        "            classify_svhn.image_transform\n",
        "        ])\n",
        "    )\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_test_loader(batch_size):\n",
        "    \"\"\"\n",
        "    Downloads (if it doesn't already exist) SVHN test into\n",
        "    [pwd]/svhn.\n",
        "\n",
        "    Returns an iterator over the tensors of the images\n",
        "    of dimension (batch_size, 3, 32, 32)\n",
        "    \"\"\"\n",
        "    testset = torchvision.datasets.SVHN(\n",
        "        SVHN_PATH, split='test',\n",
        "        download=True,\n",
        "        transform=classify_svhn.image_transform\n",
        "    )\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    return testloader\n",
        "\n",
        "\n",
        "def extract_features(classifier, data_loader):\n",
        "    \"\"\"\n",
        "    Iterator of features for each image.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        for x, _ in data_loader:\n",
        "            h = classifier.extract_features(x).numpy()\n",
        "            for i in range(h.shape[0]):\n",
        "                yield h[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6i1MVvzhMq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculate_fid_score(sample_feature_iterator,\n",
        "                        testset_feature_iterator):\n",
        "    \"\"\"\n",
        "    To be implemented by you!\n",
        "    \"\"\"\n",
        "    testset = list(testset_feature_iterator)\n",
        "    sample = list(sample_feature_iterator)\n",
        "    \n",
        "    mu_q = np.mean(sample,axis=0)\n",
        "    mu_p = np.mean(testset,axis=0)\n",
        "    sigma_q = np.cov(sample,rowvar=False)\n",
        "    sigma_p = np.cov(testset,rowvar=False)\n",
        "    \n",
        "    fid = np.linalg.norm(mu_p-mu_q,ord=2)**2 + np.trace(sigma_p + sigma_q - 2*(sigma_q*sigma_p)**0.5)\n",
        "    return fid\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXfjidSypcJG",
        "colab_type": "code",
        "outputId": "60c6a7f6-5f42-4e7d-e1eb-0bed3f897626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "waGwDRDtphJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_directory = '/content/drive/My Drive/ift6135_A3/VAE_samples/'\n",
        "trained_model = '/content/drive/My Drive/ift6135_A3/svhn_classifier.pt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ph-typ_JqyNS",
        "colab_type": "code",
        "outputId": "8e88c0d5-4d3e-425b-f5ef-dd702cd50795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = torch.load(trained_model, map_location='cpu')\n",
        "classifier.eval()\n",
        "sample_loader = get_sample_loader(sample_directory, PROCESS_BATCH_SIZE)\n",
        "sample_f = extract_features(classifier, sample_loader)\n",
        "\n",
        "test_loader = get_test_loader(PROCESS_BATCH_SIZE)\n",
        "test_f = extract_features(classifier, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YAX65B7dq-4a",
        "colab_type": "code",
        "outputId": "85ace55f-7765-4051-ee85-c786e509bdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "fid = calculate_fid_score(sample_f, test_f)\n",
        "print(\"FID score:\", fid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in sqrt\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 42711.26775143316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kpc0_7Kc0PcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}